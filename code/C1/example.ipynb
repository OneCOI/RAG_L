{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dca1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# hugging face镜像设置，如果国内环境无法使用启用该设置\n",
    "# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "import dotenv \n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import OllamaEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "301493d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本地markdown文件路径\n",
    "markdown_path = \"../../data/C1/markdown/easy-rl-chapter1.md\"\n",
    "\n",
    "# 加载本地markdown文件\n",
    "loader = UnstructuredMarkdownLoader(markdown_path)\n",
    "docs = loader.load()\n",
    "\n",
    "# print(docs)\n",
    "\n",
    "# 文本分块\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd798b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4205cd68-abe3-4ff1-8c84-2b69ef01aaeb',\n",
       " '933328e0-8acc-405a-a740-f558c5330e34',\n",
       " '25da1a07-708c-4cfd-af98-96d28fb34765',\n",
       " '4600c93c-37d0-4992-9ca6-efb585cec7f2',\n",
       " '8d071ef9-ce42-4cb7-a43f-569ef7d5b1b8',\n",
       " 'e0ecf919-b7a7-42d3-8c88-be6e3e253b16']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文本切分\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"bge-m3:latest\"\n",
    ")\n",
    "# 构建向量存储\n",
    "vectorstore = InMemoryVectorStore(embeddings)\n",
    "vectorstore.add_documents(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b33c1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 提示词模板\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"请根据下面提供的上下文信息来回答问题。\n",
    "请确保你的回答完全基于这些上下文。\n",
    "如果上下文中没有足够的信息来回答问题，请直接告知：“抱歉，我无法根据提供的上下文找到相关信息来回答此问题。”\n",
    "\n",
    "上下文:\n",
    "{context}\n",
    "\n",
    "问题: {question}\n",
    "\n",
    "回答:\"\"\"\n",
    "                                          )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb4c8419",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dotenv.load_dotenv(override=True)\n",
    "# 配置大语言模型\n",
    "llm = ChatOpenAI(\n",
    "    model=\"qwen-plus\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=2048,\n",
    "    base_url='https://dashscope.aliyuncs.com/compatible-mode/v1',\n",
    "    api_key=os.getenv('DASHSCOPE_API_KEY')\n",
    "    # api_key=\"sk-b1e8a6140c6a4fb2b7ae64b7074a09e6\"\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92682721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文中举了以下例子：\n",
      "\n",
      "1. **雅达利游戏 Breakout**：用于说明强化学习中的时间序列数据和延迟奖励问题。\n",
      "2. **Pong 游戏**：作为强化学习的经典例子，说明智能体如何通过试错学习策略，并与监督学习进行对比。\n",
      "3. **股票交易**：将买卖股票的过程视为一个强化学习过程，通过市场反馈来学习最大化奖励的策略。\n",
      "4. **自然界中的羚羊**：刚出生的羚羊通过试错学会站立和奔跑，适应环境，类比强化学习的探索过程。\n",
      "5. **AlphaGo**：强化学习算法在围棋中战胜人类顶尖棋手，展示强化学习具有超越人类表现的潜力。\n",
      "6. **选择餐馆**：用日常决策比喻探索（尝试新餐馆）与利用（去最喜欢的餐馆）的权衡。\n",
      "7. **做广告**：利用指采用已知最优广告策略，探索指尝试新策略以寻求更好效果。\n",
      "8. **挖油**：利用是在已知油田的地方开采，探索是在新地点钻探，可能失败也可能发现大油田。\n",
      "9. **玩游戏（《街头霸王》）**：利用是重复使用某个有效策略，探索是尝试新招式，可能打出“大招”。\n",
      "10. **MountainCar-v0（小车上山）**：作为 Gym 库中的具体示例，演示如何实现智能体与环境交互，包括观测空间、动作空间以及智能体决策逻辑。\n",
      "\n",
      "这些例子涵盖了自然现象、日常生活、游戏和金融等多个领域，用于帮助理解强化学习的核心概念。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 用户查询\n",
    "question = \"文中举了哪些例子？\"\n",
    "\n",
    "# 在向量存储中查询相关文档\n",
    "retrieved_docs = vectorstore.similarity_search(question, k=3)\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "answer = llm.invoke(prompt.format(question=question, context=docs_content))\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b4eda0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 201, which is longer than the specified 200\n",
      "Created a chunk of size 277, which is longer than the specified 200\n",
      "Created a chunk of size 296, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本被切分为 14 个块。\n",
      "\n",
      "--- 前5个块内容示例 ---\n",
      "============================================================\n",
      "块 1 (长度: 72): \"# 蜂医\n",
      "\n",
      "游戏《三角洲行动》中的支援型干员\n",
      "\n",
      "蜂医是2024年琳琅天上发行的《三角洲行动》中的支援型干员之一，在早期版本是唯一一个支援型干员。\"\n",
      "============================================================\n",
      "块 2 (长度: 201): \"蜂医在游戏中能够使用战术装备“激素枪”：远程治疗队友或'自我治疗'，还可以使用兵种道具“烟幕无人机”：释放长烟幕，和“蜂巢科技烟雾弹”：产生一团白色烟雾（使用激素枪对烟雾射击换变成绿色烟雾，可起到治疗作用），干员特长为“高效救援”：救援倒地队友时速度更快，在全面战场模式中约1.4秒就能救起队友，且被救起的队友能恢复更多生命值。在烽火地带中，还能够移除队友血量上限减少的负面效果。 \\[1-2]****\"\n",
      "============================================================\n",
      "块 3 (长度: 189): \"* 中文名\n",
      "\n",
      "  罗伊•斯米\n",
      "\n",
      "* 外文名\n",
      "\n",
      "  Roy smee \\[2]**\n",
      "\n",
      "* 别    名\n",
      "\n",
      "  罗伊、蜂医\n",
      "\n",
      "* 性    别\n",
      "\n",
      "  男\n",
      "\n",
      "- 登场作品\n",
      "\n",
      "  [三角洲行动](/item/%E4%B8%89%E8%A7%92%E6%B4%B2%E8%A1%8C%E5%8A%A8/63251542?fromModule=lemma_inlink)\n",
      "\n",
      "- 生    日\"\n",
      "============================================================\n",
      "块 4 (长度: 133): \"- 生    日\n",
      "\n",
      "  2008年2月23日 \\[3]**\n",
      "\n",
      "- 身    高\n",
      "\n",
      "  176 cm \\[3]**\n",
      "\n",
      "- 体    重\n",
      "\n",
      "  75 kg \\[3]**\n",
      "\n",
      "## 目录\n",
      "\n",
      "1. 1[角色设定](#1)\n",
      "2. 2[角色定位](#2)\n",
      "3. 3[技能](#3)\"\n",
      "============================================================\n",
      "块 5 (长度: 189): \"1) ▪[战术装备 - 激素枪](#3-1)\n",
      "2) ▪[战术道具 - 烟幕无人机](#3-2)\n",
      "3) ▪[战术道具 - 蜂巢科技烟雾弹](#3-3)\n",
      "\n",
      "1. ▪[干员特长 - 高效救援](#3-4)\n",
      "\n",
      "## 角色设定\n",
      "\n",
      "三角洲行动：医疗角色蜂医！让你不再为血量担忧\n",
      "\n",
      "蜂医是游戏中的一名战地医生，拥有丰富的参军履历。\n",
      "\n",
      "蜂医在干员档案中标明他有一个妻子和女儿。\n",
      "\n",
      "## 角色定位\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters  import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../../data/C2/txt/蜂医.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=200,    # 每个块的目标大小为100个字符\n",
    "    chunk_overlap=10   # 每个块之间重叠10个字符，以缓解语义割裂\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"文本被切分为 {len(chunks)} 个块。\\n\")\n",
    "print(\"--- 前5个块内容示例 ---\")\n",
    "for i, chunk in enumerate(chunks[:5]):\n",
    "    print(\"=\" * 60)\n",
    "    # chunk 是一个 Document 对象，需要访问它的 .page_content 属性来获取文本\n",
    "    print(f'块 {i+1} (长度: {len(chunk.page_content)}): \"{chunk.page_content}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "508a9e09",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_experimental.text_splitters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_experimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSemanticChunker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SemanticChunker\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_experimental.text_splitters'"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.text_splitters.SemanticChunker import SemanticChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c58e8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index has been saved to ./faiss_index_store\n",
      "\n",
      "查询: 'FAISS是做什么的？'\n",
      "相似度最高的文档:\n",
      "- FAISS是一个用于高效相似性搜索和密集向量聚类的库。\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# 1. 示例文本和嵌入模型\n",
    "texts = [\n",
    "    \"张三是法外狂徒\",\n",
    "    \"FAISS是一个用于高效相似性搜索和密集向量聚类的库。\",\n",
    "    \"LangChain是一个用于开发由语言模型驱动的应用程序的框架。\"\n",
    "]\n",
    "docs = [Document(page_content=t) for t in texts]\n",
    "embeddings=OllamaEmbeddings(\n",
    "    model=\"bge-m3:latest\"\n",
    ")\n",
    "\n",
    "# 2. 创建向量存储并保存到本地\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "local_faiss_path = \"./faiss_index_store\"\n",
    "vectorstore.save_local(local_faiss_path)\n",
    "\n",
    "print(f\"FAISS index has been saved to {local_faiss_path}\")\n",
    "\n",
    "# 3. 加载索引并执行查询\n",
    "# 加载时需指定相同的嵌入模型，并允许反序列化\n",
    "loaded_vectorstore = FAISS.load_local(\n",
    "    local_faiss_path,\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# 相似性搜索\n",
    "query = \"FAISS是做什么的？\"\n",
    "results = loaded_vectorstore.similarity_search(query, k=1)\n",
    "\n",
    "print(f\"\\n查询: '{query}'\")\n",
    "print(\"相似度最高的文档:\")\n",
    "for doc in results:\n",
    "    print(f\"- {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e21a4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
