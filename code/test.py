from langchain_community.tools import TavilySearchResults
import os
import dotenv
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader
from langchain_ollama import OllamaEmbeddings
from langchain_core.tools import create_retriever_tool
from langchain_openai import ChatOpenAI
from langchain_classic import hub
from langchain_classic.agents import create_tool_calling_agent, AgentExecutor
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.runnables import RunnableConfig
import streamlit as st
from pathlib import Path
import glob

dotenv.load_dotenv()
os.environ['TAVILY_API_KEY'] = os.getenv('TAVILY_API_KEY1')

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ³•å¾‹ RAG æ™ºèƒ½åŠ©æ‰‹",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        margin-bottom: 2rem;
        color: #1f77b4;
        padding: 1rem;
    }
    .tool-call-box {
        background-color: #f0f7ff;
        border-left: 4px solid #1f77b4;
        padding: 0.75rem;
        margin: 0.5rem 0;
        border-radius: 0.25rem;
    }
    .tool-name {
        font-weight: bold;
        color: #1f77b4;
    }
    </style>
""", unsafe_allow_html=True)

# å‘é‡æ•°æ®åº“æŒä¹…åŒ–è·¯å¾„ï¼ˆéœ€è¦åœ¨è¿™é‡Œå®šä¹‰ï¼Œä»¥ä¾¿åœ¨ä¾§è¾¹æ ä¸­ä½¿ç”¨ï¼‰
FAISS_INDEX_PATH = Path("code/faiss_legal_index")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ é…ç½®")
    
    # RAG å¼€å…³
    st.subheader("ğŸ”§ RAG è®¾ç½®")
    use_rag = st.checkbox(
        "å¯ç”¨ RAGï¼ˆæ³•å¾‹çŸ¥è¯†åº“æ£€ç´¢ï¼‰",
        value=True,
        help="å¯ç”¨åå¯ä»¥ä½¿ç”¨æ³•å¾‹çŸ¥è¯†åº“è¿›è¡Œæ£€ç´¢ï¼Œç¦ç”¨ååªèƒ½ä½¿ç”¨ç½‘ç»œæœç´¢"
    )
    
    # ç´¢å¼•ç®¡ç†
    if use_rag:
        st.divider()
        st.subheader("ğŸ“š å‘é‡æ•°æ®åº“ç®¡ç†")
        
        # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
        index_file = FAISS_INDEX_PATH / "index.faiss"
        index_pkl = FAISS_INDEX_PATH / "index.pkl"
        index_exists = index_file.exists() and index_pkl.exists()
        
        if index_exists:
            st.success("âœ… æŒä¹…åŒ–ç´¢å¼•å·²å­˜åœ¨")
            index_size = index_file.stat().st_size / (1024 * 1024)  # MB
            st.caption(f"ç´¢å¼•å¤§å°: {index_size:.2f} MB")
        else:
            st.warning("âš ï¸ æŒä¹…åŒ–ç´¢å¼•ä¸å­˜åœ¨ï¼Œå°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶æ„å»º")
        
        # é‡å»ºç´¢å¼•æŒ‰é’®
        if st.button("ğŸ”„ é‡å»ºå‘é‡æ•°æ®åº“ç´¢å¼•", use_container_width=True):
            st.session_state.rebuild_index = True
            # æ¸…é™¤æ‰€æœ‰ç›¸å…³ç¼“å­˜
            load_legal_knowledge_base.clear()
            initialize_rag_system.clear()
            # æ¸…é™¤ç¼“å­˜çš„ agent
            for key in list(st.session_state.keys()):
                if key.startswith("rag_") or key == "last_rag_setting" or key == "rag_cache_key":
                    del st.session_state[key]
            st.rerun()
    
    # ç³»ç»ŸçŠ¶æ€
    st.divider()
    st.subheader("ç³»ç»ŸçŠ¶æ€")
    if "retriever_tool" not in st.session_state and use_rag:
        st.warning("â³ æ­£åœ¨åŠ è½½æ³•å¾‹çŸ¥è¯†åº“...")
    else:
        st.success("âœ… ç³»ç»Ÿå·²å°±ç»ª")
    
    st.divider()
    
    # ä¼šè¯IDé…ç½®
    st.subheader("ğŸ“ ä¼šè¯ç®¡ç†")
    session_id = st.text_input(
        "ä¼šè¯ ID",
        value=st.session_state.get("current_session_id", "default"),
        help="ä¸åŒçš„ä¼šè¯IDå¯¹åº”ä¸åŒçš„å¯¹è¯å†å²",
        key="session_id_input"
    )
    
    # æ›´æ–°å½“å‰ä¼šè¯ID
    if "current_session_id" not in st.session_state:
        st.session_state.current_session_id = "default"
    
    if session_id != st.session_state.current_session_id:
        # ä¿å­˜å½“å‰ä¼šè¯çš„æ¶ˆæ¯
        if "messages" in st.session_state:
            if "session_messages" not in st.session_state:
                st.session_state.session_messages = {}
            st.session_state.session_messages[st.session_state.current_session_id] = st.session_state.messages.copy()
        
        # æ›´æ–°ä¼šè¯ID
        st.session_state.current_session_id = session_id
        
        # åŠ è½½æ–°ä¼šè¯çš„æ¶ˆæ¯
        if "session_messages" in st.session_state and session_id in st.session_state.session_messages:
            st.session_state.messages = st.session_state.session_messages[session_id]
        else:
            st.session_state.messages = []
    
    if st.button("ğŸ”„ åˆ·æ–°ä¼šè¯", use_container_width=True):
        st.rerun()
    
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå½“å‰ä¼šè¯", use_container_width=True):
        st.session_state.messages = []
        st.rerun()
    
    # ç»Ÿè®¡ä¿¡æ¯
    st.divider()
    st.subheader("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
    if "messages" in st.session_state:
        total_messages = len(st.session_state.messages)
        user_messages = len([m for m in st.session_state.messages if m["role"] == "user"])
        assistant_messages = len([m for m in st.session_state.messages if m["role"] == "assistant"])
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("æ€»æ¶ˆæ¯", total_messages)
        with col2:
            st.metric("ç”¨æˆ·æ¶ˆæ¯", user_messages)
        st.metric("åŠ©æ‰‹å›å¤", assistant_messages)
    
    st.divider()
    
    # å…³äºä¿¡æ¯
    st.subheader("â„¹ï¸ å…³äº")
    st.info("""
    **æ³•å¾‹ RAG æ™ºèƒ½åŠ©æ‰‹**
    
    è¿™æ˜¯ä¸€ä¸ªåŸºäº RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) çš„æ³•å¾‹æ™ºèƒ½åŠ©æ‰‹ã€‚
    
    **åŠŸèƒ½ç‰¹æ€§:**
    - ğŸ” Tavily ç½‘ç»œæœç´¢
    - ğŸ“š æ³•å¾‹çŸ¥è¯†åº“æ£€ç´¢
    - ğŸ”§ RAG å¼€å…³æ§åˆ¶
    - ğŸ› ï¸ å·¥å…·è°ƒç”¨å¯è§†åŒ–
    - ğŸ’¬ å¯¹è¯å†å²ç®¡ç†
    
    **æŠ€æœ¯æ ˆ:**
    - LangChain
    - FAISS å‘é‡æ•°æ®åº“
    - Ollama Embeddings
    - Streamlit
    """)

# ä¸»æ ‡é¢˜
st.markdown('<div class="main-header">âš–ï¸ æ³•å¾‹ RAG æ™ºèƒ½åŠ©æ‰‹</div>', unsafe_allow_html=True)

# åŠ è½½æ³•å¾‹çŸ¥è¯†åº“
@st.cache_resource
def load_legal_knowledge_base(rebuild_index=False):
    """åŠ è½½æ³•å¾‹çŸ¥è¯†åº“ï¼Œæ”¯æŒæŒä¹…åŒ–å­˜å‚¨"""
    knowledge_base_path = Path("code/knowledge_base")
    if not knowledge_base_path.exists():
        st.error(f"âŒ çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨: {knowledge_base_path}")
        return None, None
    
    # åˆ›å»ºåµŒå…¥æ¨¡å‹
    embedding_model = OllamaEmbeddings(model="bge-m3:latest")
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æŒä¹…åŒ–çš„å‘é‡æ•°æ®åº“
    index_file = FAISS_INDEX_PATH / "index.faiss"
    index_pkl = FAISS_INDEX_PATH / "index.pkl"
    
    # å¦‚æœä¸éœ€è¦é‡å»ºç´¢å¼•ä¸”æŒä¹…åŒ–æ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥åŠ è½½
    if not rebuild_index and index_file.exists() and index_pkl.exists():
        try:
            with st.spinner("ğŸ“‚ æ­£åœ¨åŠ è½½æŒä¹…åŒ–çš„å‘é‡æ•°æ®åº“..."):
                db = FAISS.load_local(
                    str(FAISS_INDEX_PATH),
                    embedding_model,
                    allow_dangerous_deserialization=True
                )
                retriever = db.as_retriever()
                st.success(f"âœ… æˆåŠŸåŠ è½½æŒä¹…åŒ–çš„å‘é‡æ•°æ®åº“")
                return retriever, db
        except Exception as e:
            st.warning(f"âš ï¸ åŠ è½½æŒä¹…åŒ–ç´¢å¼•å¤±è´¥: {str(e)}ï¼Œå°†é‡æ–°æ„å»ºç´¢å¼•...")
    
    # å¦‚æœä¸å­˜åœ¨æŒä¹…åŒ–æ–‡ä»¶æˆ–éœ€è¦é‡å»ºï¼Œåˆ™åˆ›å»ºæ–°çš„ç´¢å¼•
    with st.spinner("ğŸ”„ æ­£åœ¨æ„å»ºå‘é‡æ•°æ®åº“ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ..."):
        # è·å–æ‰€æœ‰ .txt æ–‡ä»¶
        txt_files = list(knowledge_base_path.glob("*.txt"))
        if not txt_files:
            st.error(f"âŒ çŸ¥è¯†åº“ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ° .txt æ–‡ä»¶")
            return None, None
        
        # åŠ è½½æ‰€æœ‰æ–‡æ¡£
        docs = []
        for txt_file in txt_files:
            try:
                loader = TextLoader(str(txt_file), encoding='utf-8')
                docs.extend(loader.load())
            except Exception as e:
                st.warning(f"âš ï¸ åŠ è½½æ–‡ä»¶ {txt_file.name} æ—¶å‡ºé”™: {str(e)}")
        
        if not docs:
            st.error("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ–‡æ¡£")
            return None, None
        
        # æ‹†åˆ†æ–‡æ¡£
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=100
        )
        split_docs = text_splitter.split_documents(docs)
        
        # åˆ›å»ºå‘é‡æ•°æ®åº“
        db = FAISS.from_documents(
            documents=split_docs,
            embedding=embedding_model
        )
        
        # ä¿å­˜åˆ°æœ¬åœ°
        try:
            FAISS_INDEX_PATH.mkdir(parents=True, exist_ok=True)
            db.save_local(str(FAISS_INDEX_PATH))
            st.success(f"âœ… æˆåŠŸæ„å»ºå¹¶ä¿å­˜å‘é‡æ•°æ®åº“ï¼š{len(txt_files)} ä¸ªæ³•å¾‹æ–‡æ¡£ï¼Œå…± {len(split_docs)} ä¸ªæ–‡æ¡£å—")
        except Exception as e:
            st.warning(f"âš ï¸ ä¿å­˜å‘é‡æ•°æ®åº“å¤±è´¥: {str(e)}")
        
        # åˆ›å»ºæ£€ç´¢å™¨
        retriever = db.as_retriever()
        
        return retriever, db

# åˆå§‹åŒ– RAG ç³»ç»Ÿ
@st.cache_resource
def initialize_rag_system(_use_rag, rebuild_index=False):
    """åˆå§‹åŒ– RAG ç³»ç»Ÿ"""
    try:
        # æ­¥éª¤1: åˆ›å»º Tavily æœç´¢å·¥å…·
        search = TavilySearchResults(max_results=3)
        
        tools = [search]
        
        # æ­¥éª¤2: å¦‚æœå¯ç”¨ RAGï¼ŒåŠ è½½æ³•å¾‹çŸ¥è¯†åº“
        retriever = None
        if _use_rag:
            retriever, db = load_legal_knowledge_base(rebuild_index=rebuild_index)
            if retriever is not None:
                # åˆ›å»ºæ£€ç´¢å·¥å…·
                retriever_tool = create_retriever_tool(
                    retriever=retriever,
                    name='legal_knowledge_base',
                    description='ç”¨äºæ£€ç´¢ä¸­åäººæ°‘å…±å’Œå›½æ³•å¾‹æ¡æ–‡çš„å·¥å…·ï¼Œå¯ä»¥æŸ¥è¯¢å„ç±»æ³•å¾‹çš„å…·ä½“å†…å®¹å’Œæ¡æ¬¾'
                )
                tools.append(retriever_tool)
        
        # æ­¥éª¤3: åˆ›å»ºå¤§æ¨¡å‹
        model = ChatOpenAI(
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            model="qwen-plus"
        )
        
        # æ­¥éª¤4: åˆ›å»º Agent
        prompt = hub.pull("hwchase17/openai-functions-agent")
        agent = create_tool_calling_agent(model, tools, prompt)
        
        # æ­¥éª¤5: åˆ›å»º AgentExecutorï¼ˆå¯ç”¨è¯¦ç»†è¾“å‡ºä»¥è¿½è¸ªå·¥å…·è°ƒç”¨ï¼‰
        agent_executor = AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True,
            return_intermediate_steps=True
        )
        
        # æ­¥éª¤6: åˆ›å»ºå¸¦å†å²è®°å½•çš„ Agent
        store = {}
        
        def get_session_history(session_id: str):
            if session_id not in store:
                store[session_id] = ChatMessageHistory()
            return store[session_id]
        
        agent_with_chat_history = RunnableWithMessageHistory(
            runnable=agent_executor,
            get_session_history=get_session_history,
            input_messages_key='input',
            history_messages_key='chat_history',
        )
        
        return agent_with_chat_history, store, tools
        
    except Exception as e:
        st.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return None, None, []

# åˆå§‹åŒ–ç³»ç»Ÿ
rebuild_index = st.session_state.get("rebuild_index", False)
cache_key = f"rag_{use_rag}_rebuild_{rebuild_index}"

# å¦‚æœéœ€è¦é‡å»ºç´¢å¼•ï¼Œæ¸…é™¤ç¼“å­˜
if rebuild_index:
    load_legal_knowledge_base.clear()
    initialize_rag_system.clear()
    st.session_state.rebuild_index = False

if cache_key not in st.session_state or st.session_state.get("last_rag_setting") != use_rag or rebuild_index:
    agent_with_chat_history, store, tools = initialize_rag_system(use_rag, rebuild_index=rebuild_index)
    if agent_with_chat_history is not None:
        st.session_state[cache_key] = agent_with_chat_history
        st.session_state.store = store
        st.session_state.tools = tools
        st.session_state.last_rag_setting = use_rag
        st.session_state["rag_cache_key"] = cache_key
        if use_rag:
            if rebuild_index:
                st.success("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼ï¼ˆRAG å·²å¯ç”¨ï¼Œç´¢å¼•å·²é‡å»ºï¼‰")
            else:
                st.success("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼ï¼ˆRAG å·²å¯ç”¨ï¼‰")
        else:
            st.success("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼ï¼ˆRAG å·²ç¦ç”¨ï¼‰")
    else:
        st.stop()
else:
    agent_with_chat_history = st.session_state[cache_key]
    tools = st.session_state.get("tools", [])

# åˆå§‹åŒ–æ¶ˆæ¯å†å²
if "messages" not in st.session_state:
    st.session_state.messages = []
    # æ¬¢è¿æ¶ˆæ¯
    rag_status = "å·²å¯ç”¨" if use_rag else "å·²ç¦ç”¨"
    st.session_state.messages.append({
        "role": "assistant",
        "content": f"ğŸ‘‹ æ‚¨å¥½ï¼æˆ‘æ˜¯æ³•å¾‹ RAG æ™ºèƒ½åŠ©æ‰‹ã€‚æˆ‘å¯ä»¥å¸®æ‚¨ï¼š\n\n1. ğŸ” **ç½‘ç»œæœç´¢** - å›ç­”å®æ—¶é—®é¢˜\n2. ğŸ“š **æ³•å¾‹æ£€ç´¢** - æŸ¥è¯¢ä¸­åäººæ°‘å…±å’Œå›½æ³•å¾‹æ¡æ–‡ï¼ˆRAG {rag_status}ï¼‰\n3. ğŸ› ï¸ **å·¥å…·è°ƒç”¨å¯è§†åŒ–** - æ˜¾ç¤ºæˆ‘ä½¿ç”¨çš„å·¥å…·\n4. ğŸ’¬ **å¯¹è¯äº¤æµ** - è®°ä½æˆ‘ä»¬çš„å¯¹è¯å†å²\n\nè¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Ÿ"
    })

# æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
        # å¦‚æœæ˜¯åŠ©æ‰‹æ¶ˆæ¯ä¸”åŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼Œæ˜¾ç¤ºå·¥å…·è°ƒç”¨
        if message["role"] == "assistant" and "tool_calls" in message:
            st.markdown('<div class="tool-call-box">', unsafe_allow_html=True)
            st.markdown("**ğŸ› ï¸ ä½¿ç”¨çš„å·¥å…·ï¼š**")
            for tool_call in message["tool_calls"]:
                tool_name = tool_call.get("name", "æœªçŸ¥å·¥å…·")
                st.markdown(f"- <span class='tool-name'>{tool_name}</span>", unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)

# ç”¨æˆ·è¾“å…¥
if user_input := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # ç”ŸæˆåŠ©æ‰‹å›å¤
    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤” æ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨å€™..."):
            try:
                # è·å–å½“å‰ä¼šè¯ID
                current_session_id = st.session_state.get('current_session_id', 'default')
                
                # è°ƒç”¨å¸¦å†å²è®°å½•çš„ Agent
                config = RunnableConfig(
                    configurable={'session_id': current_session_id}
                )
                
                response = agent_with_chat_history.invoke(
                    {'input': user_input},
                    config=config
                )
                
                # æå–å›å¤å†…å®¹
                response_text = response.get("output", str(response))
                
                # æå–å·¥å…·è°ƒç”¨ä¿¡æ¯
                tool_calls = []
                # å°è¯•ä» intermediate_steps ä¸­æå–å·¥å…·è°ƒç”¨
                if "intermediate_steps" in response:
                    for step in response["intermediate_steps"]:
                        if isinstance(step, (list, tuple)) and len(step) >= 1:
                            # step[0] é€šå¸¸æ˜¯ AgentAction æˆ– ToolMessage
                            action = step[0]
                            if hasattr(action, "tool"):
                                tool_name = action.tool
                            elif hasattr(action, "name"):
                                tool_name = action.name
                            elif isinstance(action, dict):
                                tool_name = action.get("tool") or action.get("name", "æœªçŸ¥å·¥å…·")
                            else:
                                tool_name = str(action)
                            if tool_name and tool_name != "æœªçŸ¥å·¥å…·":
                                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™å¢åŠ è®¡æ•°
                                existing_tool = next((tc for tc in tool_calls if tc.get("name") == tool_name), None)
                                if existing_tool:
                                    existing_tool["count"] = existing_tool.get("count", 1) + 1
                                else:
                                    tool_calls.append({"name": tool_name, "count": 1})
                
                # æ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯
                if tool_calls:
                    st.markdown('<div class="tool-call-box">', unsafe_allow_html=True)
                    st.markdown("**ğŸ› ï¸ æœ¬æ¬¡è°ƒç”¨çš„å·¥å…·ï¼š**")
                    for tool_call in tool_calls:
                        tool_name = tool_call.get("name", "æœªçŸ¥å·¥å…·")
                        count = tool_call.get("count", 1)
                        tool_display = f"- <span class='tool-name'>{tool_name}</span>"
                        if count > 1:
                            tool_display += f" (è°ƒç”¨ {count} æ¬¡)"
                        st.markdown(tool_display, unsafe_allow_html=True)
                    st.markdown('</div>', unsafe_allow_html=True)
                
                # æ˜¾ç¤ºå›å¤
                st.markdown(response_text)
                
                # ä¿å­˜åŠ©æ‰‹å›å¤ï¼ˆåŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼‰
                message_to_save = {
                    "role": "assistant",
                    "content": response_text
                }
                if tool_calls:
                    message_to_save["tool_calls"] = tool_calls
                
                st.session_state.messages.append(message_to_save)
                
            except Exception as e:
                error_message = f"âŒ æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ï¼š\n\n```\n{str(e)}\n```"
                st.error(error_message)
                st.session_state.messages.append({"role": "assistant", "content": error_message})
    
    # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
    st.rerun()

# åº•éƒ¨ä¿¡æ¯
st.divider()
rag_status_text = "å·²å¯ç”¨" if use_rag else "å·²ç¦ç”¨"
st.markdown(
    f"""
    <div style='text-align: center; color: #666; padding: 1rem;'>
        <small>
            ğŸ’¡ æç¤ºï¼šæ‚¨å¯ä»¥è¯¢é—®æ³•å¾‹ç›¸å…³é—®é¢˜ï¼Œæˆ–ä½¿ç”¨ç½‘ç»œæœç´¢åŠŸèƒ½æŸ¥è¯¢å®æ—¶ä¿¡æ¯ã€‚å½“å‰ RAG çŠ¶æ€ï¼š<strong>{rag_status_text}</strong>
        </small>
    </div>
    """,
    unsafe_allow_html=True
)